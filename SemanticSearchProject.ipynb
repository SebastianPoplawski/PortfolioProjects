{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries \nThe most important libraries needed for this project","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport spacy\nimport string\nimport gensim\nimport operator\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:13:19.902511Z","iopub.execute_input":"2022-08-29T19:13:19.903689Z","iopub.status.idle":"2022-08-29T19:13:32.867924Z","shell.execute_reply.started":"2022-08-29T19:13:19.903525Z","shell.execute_reply":"2022-08-29T19:13:32.866615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data\nWe will now load the csv comics data into the dataframe and take a quick look at the columns and data being transferred","metadata":{}},{"cell_type":"code","source":"df_comics = pd.read_csv('../input/marvel-comic-books/Marvel_Comics.csv')\ndf_comics.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:13:32.870496Z","iopub.execute_input":"2022-08-29T19:13:32.871162Z","iopub.status.idle":"2022-08-29T19:13:33.436086Z","shell.execute_reply.started":"2022-08-29T19:13:32.871126Z","shell.execute_reply":"2022-08-29T19:13:33.434569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning and preprocessing of our data\nData preprocessing is one of the most important steps in text analytics. The goal is to remove any unwanted words or characters that serve human readability, but will not contribute to better results for our model.\n\nThe following function uses regular expressions to match patterns of unwanted text and remove/replace them.","metadata":{}},{"cell_type":"code","source":"from spacy.lang.en.stop_words import STOP_WORDS\n\nspacy_nlp = spacy.load('en_core_web_sm')\n\n#creating a list of punctuation and stopwords\npunctuations = string.punctuation\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\n\n#Function to clean and process data\n\ndef spacy_tokenizer(sentence):\n \n    #removal of unnecessary single quotation marks\n    sentence = re.sub('\\'','',sentence)\n\n    #removal of digits and words containing digits\n    sentence = re.sub('\\w*\\d\\w*','',sentence)\n\n    #replacing redundant spaces with single spaces\n    sentence = re.sub(' +',' ',sentence)\n\n    #removal of unnecessary lines beginning with special characters\n    sentence = re.sub(r'\\n: \\'\\'.*','',sentence)\n    sentence = re.sub(r'\\n!.*','',sentence)\n    sentence = re.sub(r'^:\\'\\'.*','',sentence)\n    \n    #removal of non-breaking signs\n    sentence = re.sub(r'\\n',' ',sentence)\n    \n    #removing punctuation\n    sentence = re.sub(r'[^\\w\\s]',' ',sentence)\n    \n    #creation of token object\n    tokens = spacy_nlp(sentence)\n    \n    #lower, strip and lemmatization\n    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n    \n    #remove stopwords and skip words shorter than 2 characters\n    tokens = [word for word in tokens if word not in stop_words and word not in punctuations and len(word) > 2]\n    \n    #return of tokens\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:13:33.438805Z","iopub.execute_input":"2022-08-29T19:13:33.439893Z","iopub.status.idle":"2022-08-29T19:13:34.336439Z","shell.execute_reply.started":"2022-08-29T19:13:33.439841Z","shell.execute_reply":"2022-08-29T19:13:34.334901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function of cleansing and preprocessing data for comics in \"issue_description\" column. We will save the cleansed and tokenized data in a new column.","metadata":{}},{"cell_type":"code","source":"print('Cleaning and Tokenizing...')\n%time df_comics['issue_description_tokenized'] = df_comics['issue_description'].map(lambda x: spacy_tokenizer(x))\ndf_comics.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:13:34.340198Z","iopub.execute_input":"2022-08-29T19:13:34.340610Z","iopub.status.idle":"2022-08-29T19:21:05.842675Z","shell.execute_reply.started":"2022-08-29T19:13:34.340558Z","shell.execute_reply":"2022-08-29T19:21:05.841299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Storage of the tokenized column in a separate variable to facilitate operations at subsequent points and quickly view the values","metadata":{}},{"cell_type":"code","source":"marvel_comic_plot = df_comics['issue_description_tokenized']\nmarvel_comic_plot[0:5]","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:21:05.844077Z","iopub.execute_input":"2022-08-29T19:21:05.844429Z","iopub.status.idle":"2022-08-29T19:21:05.855119Z","shell.execute_reply.started":"2022-08-29T19:21:05.844396Z","shell.execute_reply":"2022-08-29T19:21:05.854132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nseries = pd.Series(np.concatenate(marvel_comic_plot)).value_counts()[:100]\nwordcloud = WordCloud(background_color='black').generate_from_frequencies(series)\n\nplt.figure(figsize=(15,15), facecolor = None)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:21:05.856637Z","iopub.execute_input":"2022-08-29T19:21:05.857014Z","iopub.status.idle":"2022-08-29T19:21:07.057145Z","shell.execute_reply.started":"2022-08-29T19:21:05.856982Z","shell.execute_reply":"2022-08-29T19:21:07.056285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a dictionary of words\nIn the next step, we will build a dictionary, in which all unique words will be given identifiers, and their frequencies will be recorded. It is worth noting that we use the gensim library to build the dictionary. In gensim, words are referred to as \"tokens,\" and the index of each word in the dictionary is called ID","metadata":{}},{"cell_type":"code","source":"from gensim import corpora\n\n#creating a word dictionary\n%time dictionary = corpora.Dictionary(marvel_comic_plot)\n\n#list of several words that can be further removed\nstoplist = set('hello and if this can would should could tell ask stop come go')\nstop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\ndictionary.filter_tokens(stop_ids)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:21:07.058385Z","iopub.execute_input":"2022-08-29T19:21:07.058899Z","iopub.status.idle":"2022-08-29T19:21:08.590845Z","shell.execute_reply.started":"2022-08-29T19:21:07.058867Z","shell.execute_reply":"2022-08-29T19:21:08.589591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once the dictionary is created, content-neutral words and additional stopwords are removed.","metadata":{}},{"cell_type":"code","source":"#Printing the top 50 entries from the dictionary with their unique token-id\ndict_tokens = [[[dictionary[key], dictionary.token2id[dictionary[key]]] for key, value in dictionary.items() if key <= 50]]\nprint (dict_tokens)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:21:08.592385Z","iopub.execute_input":"2022-08-29T19:21:08.592738Z","iopub.status.idle":"2022-08-29T19:21:08.638659Z","shell.execute_reply.started":"2022-08-29T19:21:08.592708Z","shell.execute_reply":"2022-08-29T19:21:08.637319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction (Bag of Words).\nThe bag-of-words (BoW) model, is a way of extracting features from text to use them in modeling, such as in machine learning algorithms. It is a representation that describes the occurrence of words in a document. It includes two things\n\n1. a dictionary of known words\n2. a measure of the presence of known words.\n\nThe doc2bow method iterates through all the words in the text, if the word already exists in the set, it increases the frequency count, otherwise it inserts the word into the set and sets the frequency count to 1.","metadata":{}},{"cell_type":"code","source":"corpus = [dictionary.doc2bow(desc) for desc in marvel_comic_plot]\n\nword_frequencies = [[(dictionary[id], frequency) for id, frequency in line] for line in corpus[0:3]]\n\nprint(word_frequencies)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:21:08.640255Z","iopub.execute_input":"2022-08-29T19:21:08.640616Z","iopub.status.idle":"2022-08-29T19:21:09.386845Z","shell.execute_reply.started":"2022-08-29T19:21:08.640586Z","shell.execute_reply":"2022-08-29T19:21:09.385444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Powyższe wyniki przedstawiają słownictwo wraz z ich częstotliwością.","metadata":{}},{"cell_type":"markdown","source":"Construction of the Tf-Idf and LSI model\nTf-Idf or Term frequency-Inverse Document Frequency. This is a commonly used NLP model that helps identify the most important words in each document in a collection. Once the Tf-Idf model is built, it will be passed to the LSI model and the number of features to build will be determined","metadata":{}},{"cell_type":"code","source":"%time comic_tfidf_model = gensim.models.TfidfModel(corpus, id2word=dictionary)\n%time comic_lsi_model = gensim.models.LsiModel(comic_tfidf_model[corpus], id2word=dictionary, num_topics=300)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:21:09.389870Z","iopub.execute_input":"2022-08-29T19:21:09.390487Z","iopub.status.idle":"2022-08-29T19:21:28.562713Z","shell.execute_reply.started":"2022-08-29T19:21:09.390449Z","shell.execute_reply":"2022-08-29T19:21:28.560970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is a good idea to serialize and store the collection locally so that it can be easily retrieved when needed.","metadata":{}},{"cell_type":"code","source":"%time gensim.corpora.MmCorpus.serialize('comic_tfidf_model_mm', comic_tfidf_model[corpus])\n%time gensim.corpora.MmCorpus.serialize('comic_lsi_model_mm',comic_lsi_model[comic_tfidf_model[corpus]])","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:21:28.565924Z","iopub.execute_input":"2022-08-29T19:21:28.567199Z","iopub.status.idle":"2022-08-29T19:22:03.115919Z","shell.execute_reply.started":"2022-08-29T19:21:28.567128Z","shell.execute_reply":"2022-08-29T19:22:03.114489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading the indexed collection\ncomic_tfidf_corpus = gensim.corpora.MmCorpus('comic_tfidf_model_mm')\ncomic_lsi_corpus = gensim.corpora.MmCorpus('comic_lsi_model_mm')\n\nprint(comic_tfidf_corpus)\nprint(comic_lsi_corpus)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:22:03.117585Z","iopub.execute_input":"2022-08-29T19:22:03.117986Z","iopub.status.idle":"2022-08-29T19:22:03.139317Z","shell.execute_reply.started":"2022-08-29T19:22:03.117952Z","shell.execute_reply":"2022-08-29T19:22:03.137991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.similarities import MatrixSimilarity\n\n%time comic_index = MatrixSimilarity(comic_lsi_corpus, num_features = comic_lsi_corpus.num_terms)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:22:03.141860Z","iopub.execute_input":"2022-08-29T19:22:03.142384Z","iopub.status.idle":"2022-08-29T19:22:15.804498Z","shell.execute_reply.started":"2022-08-29T19:22:03.142335Z","shell.execute_reply":"2022-08-29T19:22:15.803371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Semantic search\nHaving an index of comics initialized and loaded, we can use it to find similar comics\n\nEntering a query, the model will return us the corresponding comic book titles along with \"Relevance %\", which is the degree of similarity. The higher the similarity score, the more similar the query is to the document in the given index.\n\nBelow is a helper function to search the index, sort and return the results","metadata":{}},{"cell_type":"code","source":"from operator import itemgetter\n\ndef search_similar_comics(search_term):\n\n    query_bow = dictionary.doc2bow(spacy_tokenizer(search_term))\n    query_tfidf = comic_tfidf_model[query_bow]\n    query_lsi = comic_lsi_model[query_tfidf]\n\n    comic_index.num_best = 5\n\n    comic_list = comic_index[query_lsi]\n\n    comic_list.sort(key=itemgetter(1), reverse=True)\n    comic_names = []\n\n    for j, comic in enumerate(comic_list):\n\n        comic_names.append (\n            {\n                'Relevance': round((comic[1] * 100),2),\n                'Comic Title': df_comics['comic_name'][comic[0]],\n                'Comic Plot': df_comics['issue_description'][comic[0]]\n            }\n\n        )\n        if j == (comic_index.num_best-1):\n            break\n\n    return pd.DataFrame(comic_names, columns=['Relevance','Comic Title','Comic Plot'])","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:22:15.805853Z","iopub.execute_input":"2022-08-29T19:22:15.806300Z","iopub.status.idle":"2022-08-29T19:22:15.815870Z","shell.execute_reply.started":"2022-08-29T19:22:15.806267Z","shell.execute_reply":"2022-08-29T19:22:15.814556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Search for comic book titles, which are associated with the following search parameters\nsearch_similar_comics('Shield')","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:22:15.818388Z","iopub.execute_input":"2022-08-29T19:22:15.819276Z","iopub.status.idle":"2022-08-29T19:22:15.867262Z","shell.execute_reply.started":"2022-08-29T19:22:15.819236Z","shell.execute_reply":"2022-08-29T19:22:15.865600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Search for comic book titles, which are associated with the following search parameters\nsearch_similar_comics('God')","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:22:15.875583Z","iopub.execute_input":"2022-08-29T19:22:15.877117Z","iopub.status.idle":"2022-08-29T19:22:15.918545Z","shell.execute_reply.started":"2022-08-29T19:22:15.877048Z","shell.execute_reply":"2022-08-29T19:22:15.916911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Search for comic book titles, which are associated with the following search parameters\nsearch_similar_comics('Wolverine')","metadata":{"execution":{"iopub.status.busy":"2022-08-29T19:22:15.921351Z","iopub.execute_input":"2022-08-29T19:22:15.922666Z","iopub.status.idle":"2022-08-29T19:22:15.964138Z","shell.execute_reply.started":"2022-08-29T19:22:15.922593Z","shell.execute_reply":"2022-08-29T19:22:15.962421Z"},"trusted":true},"execution_count":null,"outputs":[]}]}